{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "img_path = cwd + \"\\\\sample_input_image.jpg\"\n",
    "vid_path = cwd + \"\\\\pedestrian_survaillance.mp4\"\n",
    "img = cv2.imread(img_path)\n",
    "classes = [\"None\", \"Person\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model = tf.saved_model.load(\"ssd_mobilenet_v1_coco_2018_01_28\")\n",
    "model = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(model, image, clas):\n",
    "    cent = []\n",
    "    imagenp = image\n",
    "    width = imagenp.shape[1]\n",
    "    height = imagenp.shape[0]\n",
    "    imagenp = np.expand_dims(imagenp, axis=0)\n",
    "    imagenp = tf.convert_to_tensor(imagenp)\n",
    "    pred = model(imagenp)\n",
    "\n",
    "    for x in range(pred['detection_boxes'][0].shape[0]):\n",
    "        det_score = pred['detection_scores'][0][x].numpy()\n",
    "        \n",
    "        if det_score <= 0.0:\n",
    "            g = image\n",
    "            continue\n",
    "        elif det_score >= 0.85:\n",
    "\n",
    "            ymin,xmin,ymax,xmax=pred['detection_boxes'][0][x].numpy()\n",
    "\n",
    "            (left, right, top, bottom) = (int(round((xmin * width))), int(round((xmax * width))),\n",
    "                                          int(round((ymin * height))), int(round((ymax * height))))\n",
    "\n",
    "            #crop = image[top:bottom, left:right]\n",
    "\n",
    "            cl = int(pred['detection_classes'][0][x].numpy())\n",
    "\n",
    "\n",
    "            cx = int(round((right - left)/2)) + left\n",
    "            cy = int(round((bottom - top)/2)) + top\n",
    "\n",
    "            cv2.putText(image, \"{}, {}%\".format(clas[cl], int(round(float(det_score), 2)*100)), \n",
    "                        (cx - 50 , cy), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            cv2.circle(image, (cx, cy), 5, (0, 255, 0), -1)\n",
    "            g = cv2.rectangle(image, (left, top), (right, bottom), color=(0, 255, 0), thickness=1)\n",
    "            \n",
    "            cent.append((cx, cy))\n",
    "                        \n",
    "    return g, cent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cv2.VideoCapture(vid_path)\n",
    "framecount = 0\n",
    "while cv.isOpened():\n",
    "    ret, frame = cv.read()\n",
    "    framecount += 1\n",
    "\n",
    "    if ret:\n",
    "        f = draw_bounding_boxes(model, frame, classes)\n",
    "        cv2.imshow(\"Reading\", f)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv.release()\n",
    "cv2. destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, cent2 = draw_bounding_boxes(model, img, classes)\n",
    "\n",
    "# try:\n",
    "#     cv2.imshow(\"x\", f)\n",
    "#     key = cv2.waitKey(33)\n",
    "# except:\n",
    "#     cv2. destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 554  372]\n",
      " [ 778  347]\n",
      " [ 153  370]\n",
      " [1037  345]]\n",
      "[[ 774  343]\n",
      " [ 558  367]\n",
      " [1036  347]\n",
      " [ 149  373]]\n"
     ]
    }
   ],
   "source": [
    "cent = np.array(cent)\n",
    "cent2 = np.array(cent2)\n",
    "print(cent)\n",
    "print(cent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dist.cdist(cent, cent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[221.90313202   6.40312424 482.64790479 405.00123457]\n",
      " [  5.65685425 220.90722034 258.         629.53713155]\n",
      " [621.58667939 405.01111096 883.29949621   5.        ]\n",
      " [263.00760445 479.50495305   2.23606798 888.44133177]]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 1 0]\n",
      "[2 3 0 1]\n"
     ]
    }
   ],
   "source": [
    "rows = Y.min(axis=1).argsort()\n",
    "cols = Y.argmin(axis=1)[rows]\n",
    "print(rows)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2\n",
      "2 3\n",
      "1 0\n",
      "0 1\n"
     ]
    }
   ],
   "source": [
    "for aw, awaw in zip(rows, cols):\n",
    "    print(aw, awaw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
